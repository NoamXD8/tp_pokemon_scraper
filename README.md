# PokÃ© Scraper ğŸ

## ğŸ¯ Objectif du projet
Lâ€™objectif Ã©tait de mettre en place une infrastructure simple sur **AWS** permettant :
- de scraper les images de PokÃ©mon depuis **Bulbapedia**,
- de les stocker automatiquement dans un **bucket S3 public**,
- en utilisant un script Python exÃ©cutÃ© sur une **instance EC2**.

---

## âš™ï¸ Architecture mise en place
1. CrÃ©ation dâ€™un **utilisateur IAM** (`noam_tp`) avec les droits nÃ©cessaires (S3FullAccess + EC2FullAccess).
2. CrÃ©ation dâ€™un **rÃ´le IAM pour EC2**, afin de permettre Ã  lâ€™instance dâ€™accÃ©der directement Ã  S3 sans stocker de clÃ©s dans le code.
3. DÃ©ploiement dâ€™une **instance EC2 (Ubuntu)** oÃ¹ ont Ã©tÃ© installÃ©s Python et les bibliothÃ¨ques (`requests`, `beautifulsoup4`, `boto3`).
4. DÃ©veloppement dâ€™un **script Python (`scraper.py`)** qui :
   - scrape les images par gÃ©nÃ©ration (Gen I â†’ Gen IX),
   - tÃ©lÃ©charge temporairement chaque image,
   - lâ€™upload dans S3 via `boto3`,
   - organise les fichiers selon la structure demandÃ©e :
     ```
     images/genI/...
     images/genII/...
     ...
     images/genIX/...
     ```
5. Mise en place dâ€™une **Bucket Policy publique** pour autoriser lâ€™accÃ¨s uniquement au dossier `images/*`.

---

## ğŸ–¥ï¸ Fonctionnement du script
- `requests` â†’ rÃ©cupÃ¨re le HTML de la page Bulbapedia.  
- `BeautifulSoup` â†’ extrait les URLs dâ€™images et identifie les gÃ©nÃ©rations.  
- TÃ©lÃ©chargement local temporaire sur lâ€™EC2.  
- `boto3` â†’ envoie les fichiers vers le bucket S3.  
- Suppression des fichiers temporaires aprÃ¨s upload.  

Chaque image devient accessible publiquement via une URL, par exemple :  
